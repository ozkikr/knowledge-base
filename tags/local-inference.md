# local-inference

*3 notes*

- [[notes/github/exo|exo - Run Frontier AI Locally]]
- [[notes/github/mlx-omni-server|MLX Omni Server]]
- [[notes/github/yzma|yzma]]

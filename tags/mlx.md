# mlx

*5 notes*

- [[notes/github/exo|exo - Run Frontier AI Locally]]
- [[notes/github/mlx-lm|MLX LM]]
- [[notes/github/mlx-lora-finetune-template|MLX LoRA Fine-tuning Engine]]
- [[notes/github/mlx-omni-server|MLX Omni Server]]
- [[notes/github/swama|Swama]]

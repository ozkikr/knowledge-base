# transformers

*5 notes*

- [[notes/articles/nn-attention-and-transformers-bactra|"Attention", "Transformers", in Neural Network "Large Language Models"]]
- [[notes/articles/from-multi-head-to-latent-attention|From Multi-Head to Latent Attention: The Evolution of Attention Mechanisms]]
- [[notes/articles/how-llm-inference-works|How LLM Inference Works]]
- [[notes/articles/neural-networks-zero-to-hero|Neural Networks: Zero to Hero]]
- [[notes/articles/the-q-k-v-matrices|The Q, K, V Matrices]]

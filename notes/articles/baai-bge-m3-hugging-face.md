---
url: https://huggingface.co/BAAI/bge-m3
type: paper
tags: [embedding-models, multilingual, retrieval]
date_saved: 2026-02-15
---
# BAAI/bge-m3 Â· Hugging Face
## Summary
This model card introduces BGE-M3, a multilingual retrieval model designed for multi-functionality across dense, sparse, and multi-vector modes. It supports long inputs up to 8192 tokens and is positioned for hybrid retrieval pipelines in RAG systems. The page includes usage patterns, implementation guidance, and links to the associated paper and code.

## Key Points
- Unifies dense retrieval, lexical/sparse matching, and ColBERT-style token interaction in one model.
- Supports 100+ languages and long-context retrieval tasks.
- Recommends combining hybrid retrieval with reranking for better end-to-end RAG quality.
- Provides practical examples for generating dense, sparse, and multi-vector outputs.
- Links to evaluation updates, datasets, and fine-tuning resources for advanced use cases.

## Related
- [[BGE-M3]]
- [[Multilingual Retrieval]]
- [[Reranking]]

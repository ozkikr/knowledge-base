---
url: https://moondream.ai/blog/moondream-3-preview
type: article
tags: [vision-language-model, edge-ai, moe]
date_saved: 2026-02-14
---
# Moondream 3 Preview

## Summary
Moondream 3 is a 9B MoE vision-language model with only 2B active parameters, achieving frontier-level visual reasoning while maintaining fast and efficient inference. It targets real-world physical AI applications like robotics and inspection.

## Key Points
- 9B MoE architecture with 2B active parameters for speed and cost efficiency
- Achieves frontier-level visual reasoning benchmarks
- Context length grew from 2k to 32k tokens
- Designed to be easily trainable including with reinforcement learning
- Targets physical-world AI: robotics, drones, security, produce sorting

## Related
- [[whisperclip]] - Local AI processing on device
- [[PageIndex]] - Vision-based document RAG

---
url: https://ollama.com/Inference/Schematron
type: article
tags: [llm, ollama, extraction, json-schema]
date_saved: 2026-02-15
---
# Inference/Schematron
## Summary
Model card and usage guide for Schematron, a fine-tuned Llama 3.2-3B model for HTML-to-JSON extraction with schema-constrained output.

## Key Points
- Explains local Ollama usage vs serverless API usage, with different prompt expectations.
- Recommends temperature 0 and a strict prompt template for reliable structured output.
- Provides cURL, Python, and JavaScript examples for schema-driven extraction.
- Suggests cleaning noisy HTML before extraction and includes an lxml cleaning snippet.
- Includes troubleshooting guidance for prompt format, long/noisy HTML, and output quality.

## Related
- Structured outputs for LLMs
- Information extraction pipelines
- Schema-first prompt design

---
url: https://medium.com/whatnot-engineering/lessons-learned-from-scaling-data-scientists-with-ai-e7aa7b3235b4
type: article
tags: [data-science, llm, analytics, context-engineering, enterprise-ai]
date_saved: 2026-02-15
---
# Lessons learned from scaling data scientists with AI
## Summary
An engineering retrospective on deploying an LLM-powered data-assistant at Whatnot, highlighting adoption wins and architecture lessons around trust, constrained context, and semantic modeling.

## Key Points
- The bot shifted internal support from manual data-team responses to AI-first self-service.
- Early design prioritized correctness over flexibility by constraining access to vetted semantic layers.
- Semantic views and curated data context significantly improved SQL-generation reliability.
- The team reframed the problem as ongoing context governance rather than one-time assistant deployment.

## Related
- [[llm-observability-datadog-nlq]]
- [[why-analytics-agents-break-differently]]

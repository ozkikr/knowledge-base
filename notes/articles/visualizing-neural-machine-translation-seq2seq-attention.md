---
url: https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/
type: article
tags: [seq2seq, attention, neural-machine-translation, deep-learning, visualization]
date_saved: 2026-02-14
---
# Visualizing A Neural Machine Translation Model (Mechanics of Seq2seq Models With Attention)

## Summary
Jay Alammar's visual guide to sequence-to-sequence models and the attention mechanism used in neural machine translation. It explains encoder-decoder architecture, context vectors, word embeddings, and how attention allows the decoder to focus on relevant parts of the input.

## Key Points
- Seq2seq models use an encoder to compress input into a context vector and a decoder to produce output
- The context vector bottleneck limits performance on long sequences
- Attention mechanism lets the decoder look at all encoder hidden states, not just the final one
- Word embeddings transform words into vectors for neural network processing
- Referenced in MIT's Deep Learning State of the Art lecture

## Related
- [[transformers]] [[attention-mechanism]] [[encoder-decoder]] [[word-embeddings]]

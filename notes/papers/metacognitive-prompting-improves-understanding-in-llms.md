---
url: https://arxiv.org/abs/2308.05342
type: paper
tags: [prompting, metacognition, nlu, chain-of-thought, llm-reasoning]
date_saved: 2026-02-14
---
# Metacognitive Prompting Improves Understanding in Large Language Models

## Summary
This NAACL 2024 paper introduces Metacognitive Prompting (MP), a strategy inspired by human introspective reasoning. LLMs undergo structured, self-aware evaluations drawing on inherent knowledge and new insights. MP consistently outperforms chain-of-thought and its variants across NLU benchmarks.

## Key Points
- Introduces Metacognitive Prompting (MP) inspired by human introspective reasoning
- Tested on Llama2, PaLM2, GPT-3.5, GPT-4 across 10 NLU datasets (GLUE, SuperGLUE, BLUE, LexGLUE)
- Outperforms chain-of-thought prompting and advanced variants
- GPT-4 excels across all tasks; other models show significant gains with MP
- Published at NAACL 2024

## Related
- [[chain-of-thought]] [[prompt-engineering]] [[NLU]] [[reasoning]]

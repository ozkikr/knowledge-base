---
url: https://github.com/Mozilla-Ocho/llamafile
type: github-repo
tags: [llm, local-ai, single-file, mozilla]
date_saved: 2026-02-14
---
# llamafile

## Summary
llamafile lets you distribute and run LLMs with a single executable file. It combines llama.cpp with Cosmopolitan Libc to create portable executables that run locally on most computers with no installation. Now maintained by Mozilla AI.

## Key Points
- Single-file LLM distribution and execution â€” no installation needed
- Combines llama.cpp + Cosmopolitan Libc for cross-platform portability
- Runs on macOS, Linux, Windows, BSD from same binary
- Includes built-in web UI that opens in browser automatically
- Recently adopted by Mozilla AI for continued development

## Related
- [[llama-cpp]] - Underlying LLM inference engine
- [[cosmopolitan-libc]] - Cross-platform binary technology
- [[local-llm]] - Running LLMs locally

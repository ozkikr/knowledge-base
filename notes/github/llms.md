---
url: https://github.com/ServiceStack/llms
type: github-repo
languages: [JavaScript, Python, CSS, Shell, Dockerfile]
tags: [llm-ui, offline, multi-provider]
date_saved: 2026-02-15
---
# llms.py
## Summary
llms.py is presented as a lightweight CLI/API and ChatGPT-like interface for working with multiple LLMs in a private, offline-first style. It positions browser storage and local operation as core design choices for data privacy.

## Key Points
- Provides command-line and web-style interface options for model access.
- Targets multi-model workflows in a compact deployment footprint.
- Emphasizes offline-capable usage and local data retention.
- Serves as an alternative path to heavier self-hosted UI stacks.
- Linked project documentation and UI assets are hosted at llmspy.org.

## Related
- [[LLM Clients]]
- [[Self-Hosted AI]]
- [[Offline AI]]

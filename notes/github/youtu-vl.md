---
url: https://github.com/TencentCloudADP/youtu-vl
type: github-repo
languages: [Python]
tags: [vision-language-model, multimodal, research]
date_saved: 2026-02-15
---
# Youtu-VL
## Summary
Youtu-VL is a 4B-parameter vision-language model that emphasizes strong visual reasoning and dense vision capability. The repository introduces a unified autoregressive supervision approach (VLUAS) to improve visual signal learning in multimodal generation. It provides model checkpoints and usage instructions for practical experimentation.

## Key Points
- Proposes Vision-Language Unified Autoregressive Supervision (VLUAS) as the core training idea.
- Targets both traditional multimodal tasks and vision-centric tasks in a single model family.
- Publishes Hugging Face model artifacts, including standard and GGUF variants.
- Documents architecture and benchmark performance across broad evaluation categories.
- Includes quickstart examples using the Transformers ecosystem.

## Related
- [[Vision-Language Models]]
- [[Multimodal Learning]]
- [[Autoregressive Models]]

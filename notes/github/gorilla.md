---
url: https://github.com/ShishirPatil/gorilla
type: github-repo
tags: [llm, function-calling, tool-use, benchmarks, api]
date_saved: 2026-02-14
---
# Gorilla: LLM Connected with Massive APIs

## Summary
A research project from UC Berkeley focused on training and evaluating LLMs for function/tool calling. Includes the Berkeley Function Calling Leaderboard (BFCL), which benchmarks models on tool selection accuracy, multi-turn interactions, and agentic scenarios.

## Key Points
- BFCL V4 Agentic (2025) benchmarks tool-calling in real-world agentic settings: web search with multi-hop reasoning, agent memory, format sensitivity
- GoEx runtime enables post-facto validation, undo, and damage confinement for LLM-generated actions
- RAFT: adapting language models to domain-specific RAG
- Agent Arena (with LMSYS): community-driven comparison of agents across tasks like search, finance, RAG
- Tracks cost and latency metrics alongside accuracy on the leaderboard

## Related
- [[function-calling]]
- [[tool-use]]
- [[llm-benchmarks]]
- [[ai-agents]]

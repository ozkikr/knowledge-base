---
url: https://github.com/maximhq/bifrost
type: github-repo
languages: [Go, TypeScript]
tags: [ai-gateway, llm, load-balancer, openai-compatible, enterprise]
date_saved: 2026-02-14
---
# Bifrost AI Gateway

## Summary
Bifrost is a high-performance AI gateway claiming to be 50x faster than LiteLLM, with <100Âµs overhead at 5k RPS. It unifies access to 15+ LLM providers (OpenAI, Anthropic, AWS Bedrock, Google Vertex) through a single OpenAI-compatible API with automatic failover, load balancing, and semantic caching.

## Key Points
- Single OpenAI-compatible API for 15+ providers with zero-config deployment
- Adaptive load balancer with cluster mode for enterprise deployments
- Built-in web UI for visual configuration, real-time monitoring, and analytics
- Supports guardrails and semantic caching out of the box
- Available via npx, Docker, or Go SDK

## Related
- [[LiteLLM]]
- [[AI Gateway]]
- [[OpenAI API]]
